{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPeQRaFk15mq0sFLQ/+eEu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guifav/emails_analysis/blob/main/Quando_os_maiores_portais_e_redes_sociais_do_mundo_enviam_emails.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fds7Jd_7Ko8-"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# AN√ÅLISE PARA LINKEDIN: HOR√ÅRIOS DOS GIGANTES\n",
        "# \"Quando os maiores portais e redes sociais do mundo enviam emails?\"\n",
        "# =============================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from collections import defaultdict, Counter\n",
        "from email.utils import parsedate_to_datetime\n",
        "import time\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "MBOX_FILE = \"/content/drive/MyDrive/temp/Todos os e-mails, incluindo Spam e Lixeira-002.mbox\"\n",
        "BRT = timezone(timedelta(hours=-3))\n",
        "\n",
        "# =============================================================================\n",
        "# DEFINI√á√ÉO DOS GRUPOS\n",
        "# =============================================================================\n",
        "\n",
        "# Portais de not√≠cias (dom√≠nio ou parte do from)\n",
        "NEWS_PORTALS = {\n",
        "    # Internacionais\n",
        "    'nytimes': 'The New York Times',\n",
        "    'new york times': 'The New York Times',\n",
        "    'theinformation': 'The Information',\n",
        "    'wsj.com': 'Wall Street Journal',\n",
        "    'wall street journal': 'Wall Street Journal',\n",
        "    'washingtonpost': 'Washington Post',\n",
        "    'bloomberg': 'Bloomberg',\n",
        "    'reuters': 'Reuters',\n",
        "    'bbc': 'BBC',\n",
        "    'cnn': 'CNN',\n",
        "    'theguardian': 'The Guardian',\n",
        "    'economist': 'The Economist',\n",
        "    'ft.com': 'Financial Times',\n",
        "    'financial times': 'Financial Times',\n",
        "    'forbes': 'Forbes',\n",
        "    'techcrunch': 'TechCrunch',\n",
        "    'wired': 'Wired',\n",
        "    'theverge': 'The Verge',\n",
        "    'axios': 'Axios',\n",
        "    'politico': 'Politico',\n",
        "    'morning brew': 'Morning Brew',\n",
        "    'morningbrew': 'Morning Brew',\n",
        "    'theatlantic': 'The Atlantic',\n",
        "    'newyorker': 'The New Yorker',\n",
        "    'time.com': 'TIME',\n",
        "    'huffpost': 'HuffPost',\n",
        "    'businessinsider': 'Business Insider',\n",
        "    'cnbc': 'CNBC',\n",
        "    'fortune': 'Fortune',\n",
        "    'fastcompany': 'Fast Company',\n",
        "    'inc.com': 'Inc.',\n",
        "    'venturebeat': 'VentureBeat',\n",
        "    'mit technology': 'MIT Technology Review',\n",
        "    'technologyreview': 'MIT Technology Review',\n",
        "    'hbr.org': 'Harvard Business Review',\n",
        "    'harvard business': 'Harvard Business Review',\n",
        "\n",
        "    # Brasil\n",
        "    'valor': 'Valor Econ√¥mico',\n",
        "    'globo': 'O Globo / G1',\n",
        "    'folha': 'Folha de S.Paulo',\n",
        "    'estadao': 'Estad√£o',\n",
        "    'uol': 'UOL',\n",
        "    'exame': 'Exame',\n",
        "    'infomoney': 'InfoMoney',\n",
        "    'startse': 'StartSe',\n",
        "    'neofeed': 'NeoFeed',\n",
        "    'braziljournal': 'Brazil Journal',\n",
        "    'meioemensagem': 'Meio & Mensagem',\n",
        "\n",
        "    # Tech/Startup\n",
        "    'startupgrind': 'Startup Grind',\n",
        "    'startup grind': 'Startup Grind',\n",
        "    'ycombinator': 'Y Combinator',\n",
        "    'producthunt': 'Product Hunt',\n",
        "    'techstars': 'Techstars',\n",
        "    'sequoia': 'Sequoia Capital',\n",
        "    'a]6z': 'Andreessen Horowitz',\n",
        "    'a]6z.com': 'Andreessen Horowitz',\n",
        "}\n",
        "\n",
        "# Consultorias\n",
        "CONSULTING = {\n",
        "    'mckinsey': 'McKinsey & Company',\n",
        "    'bain.com': 'Bain & Company',\n",
        "    'bain ': 'Bain & Company',\n",
        "    'bcg.com': 'Boston Consulting Group',\n",
        "    'boston consulting': 'Boston Consulting Group',\n",
        "    'ey.com': 'EY (Ernst & Young)',\n",
        "    'ernst & young': 'EY (Ernst & Young)',\n",
        "    'deloitte': 'Deloitte',\n",
        "    'pwc': 'PwC',\n",
        "    'kpmg': 'KPMG',\n",
        "    'accenture': 'Accenture',\n",
        "    'gartner': 'Gartner',\n",
        "    'forrester': 'Forrester',\n",
        "}\n",
        "\n",
        "# Redes sociais\n",
        "SOCIAL_NETWORKS = {\n",
        "    'linkedin': 'LinkedIn',\n",
        "    'youtube': 'YouTube',\n",
        "    'facebook': 'Facebook',\n",
        "    'facebookmail': 'Facebook',\n",
        "    'meta.com': 'Meta',\n",
        "    'twitter': 'Twitter/X',\n",
        "    'x.com': 'Twitter/X',\n",
        "    'instagram': 'Instagram',\n",
        "    'snapchat': 'Snapchat',\n",
        "    'tiktok': 'TikTok',\n",
        "    'pinterest': 'Pinterest',\n",
        "    'reddit': 'Reddit',\n",
        "    'discord': 'Discord',\n",
        "    'slack': 'Slack',\n",
        "    'whatsapp': 'WhatsApp',\n",
        "    'telegram': 'Telegram',\n",
        "    'medium': 'Medium',\n",
        "    'substack': 'Substack',\n",
        "    'threads': 'Threads',\n",
        "    'quora': 'Quora',\n",
        "}\n",
        "\n",
        "# Tech Giants\n",
        "TECH_GIANTS = {\n",
        "    'google': 'Google',\n",
        "    'apple': 'Apple',\n",
        "    'microsoft': 'Microsoft',\n",
        "    'amazon': 'Amazon',\n",
        "    'openai': 'OpenAI',\n",
        "    'anthropic': 'Anthropic',\n",
        "    'netflix': 'Netflix',\n",
        "    'spotify': 'Spotify',\n",
        "    'salesforce': 'Salesforce',\n",
        "    'hubspot': 'HubSpot',\n",
        "    'dropbox': 'Dropbox',\n",
        "    'notion': 'Notion',\n",
        "    'figma': 'Figma',\n",
        "    'canva': 'Canva',\n",
        "    'zoom': 'Zoom',\n",
        "    'stripe': 'Stripe',\n",
        "    'shopify': 'Shopify',\n",
        "}\n",
        "\n",
        "print(\"üìÇ Processando emails...\")\n",
        "\n",
        "# Estruturas de dados\n",
        "all_senders = []  # (timestamp, from, category, source_name)\n",
        "category_data = defaultdict(list)  # category -> list of timestamps\n",
        "source_data = defaultdict(list)     # source_name -> list of timestamps\n",
        "\n",
        "email_count = 0\n",
        "matched_count = 0\n",
        "start_time = time.time()\n",
        "\n",
        "def categorize_sender(from_field):\n",
        "    \"\"\"Retorna (categoria, nome_fonte) ou (None, None)\"\"\"\n",
        "    from_lower = from_field.lower()\n",
        "\n",
        "    for key, name in NEWS_PORTALS.items():\n",
        "        if key in from_lower:\n",
        "            return ('Portais de Not√≠cias', name)\n",
        "\n",
        "    for key, name in CONSULTING.items():\n",
        "        if key in from_lower:\n",
        "            return ('Consultorias', name)\n",
        "\n",
        "    for key, name in SOCIAL_NETWORKS.items():\n",
        "        if key in from_lower:\n",
        "            return ('Redes Sociais', name)\n",
        "\n",
        "    for key, name in TECH_GIANTS.items():\n",
        "        if key in from_lower:\n",
        "            return ('Big Techs', name)\n",
        "\n",
        "    return (None, None)\n",
        "\n",
        "with open(MBOX_FILE, 'rb') as f:\n",
        "    in_header = False\n",
        "    current_date = None\n",
        "    current_from = None\n",
        "\n",
        "    for line in f:\n",
        "        try:\n",
        "            if line.startswith(b'From '):\n",
        "                if current_date and current_from:\n",
        "                    category, source_name = categorize_sender(current_from)\n",
        "                    if category:\n",
        "                        all_senders.append((current_date, current_from, category, source_name))\n",
        "                        category_data[category].append(current_date)\n",
        "                        source_data[source_name].append(current_date)\n",
        "                        matched_count += 1\n",
        "\n",
        "                in_header = True\n",
        "                current_date = None\n",
        "                current_from = None\n",
        "                email_count += 1\n",
        "\n",
        "                if email_count % 10000 == 0:\n",
        "                    elapsed = time.time() - start_time\n",
        "                    rate = email_count / elapsed if elapsed > 0 else 0\n",
        "                    print(f\"   {email_count:,} emails | {matched_count:,} matches ({rate:.0f}/s)\")\n",
        "                continue\n",
        "\n",
        "            if line.strip() == b'':\n",
        "                in_header = False\n",
        "                continue\n",
        "\n",
        "            if in_header:\n",
        "                line_lower = line.lower()\n",
        "\n",
        "                if line_lower.startswith(b'date:'):\n",
        "                    date_str = line[5:].decode('utf-8', errors='ignore').strip()\n",
        "                    try:\n",
        "                        dt = parsedate_to_datetime(date_str)\n",
        "                        current_date = dt.astimezone(BRT)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                elif line_lower.startswith(b'from:'):\n",
        "                    current_from = line[5:].decode('utf-8', errors='ignore').strip()\n",
        "\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# √öltimo email\n",
        "if current_date and current_from:\n",
        "    category, source_name = categorize_sender(current_from)\n",
        "    if category:\n",
        "        all_senders.append((current_date, current_from, category, source_name))\n",
        "        category_data[category].append(current_date)\n",
        "        source_data[source_name].append(current_date)\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"\\n‚úÖ {elapsed/60:.1f} min | {email_count:,} emails | {matched_count:,} de grandes players\")\n",
        "\n",
        "DIAS_PT = {0: 'Seg', 1: 'Ter', 2: 'Qua', 3: 'Qui', 4: 'Sex', 5: 'S√°b', 6: 'Dom'}\n",
        "DIAS_FULL = {0: 'Segunda', 1: 'Ter√ßa', 2: 'Quarta', 3: 'Quinta', 4: 'Sexta', 5: 'S√°bado', 6: 'Domingo'}\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURA√á√ÉO VISUAL PARA LINKEDIN\n",
        "# =============================================================================\n",
        "\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.facecolor'] = '#0a0a0a'\n",
        "plt.rcParams['axes.facecolor'] = '#0a0a0a'\n",
        "plt.rcParams['axes.edgecolor'] = '#333333'\n",
        "plt.rcParams['axes.labelcolor'] = 'white'\n",
        "plt.rcParams['text.color'] = 'white'\n",
        "plt.rcParams['xtick.color'] = 'white'\n",
        "plt.rcParams['ytick.color'] = 'white'\n",
        "plt.rcParams['grid.color'] = '#333333'\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "COLORS = {\n",
        "    'Portais de Not√≠cias': '#FF6B6B',\n",
        "    'Redes Sociais': '#4ECDC4',\n",
        "    'Consultorias': '#FFE66D',\n",
        "    'Big Techs': '#95E1D3',\n",
        "}\n",
        "\n",
        "# =============================================================================\n",
        "# GR√ÅFICO 1: VIS√ÉO GERAL POR CATEGORIA\n",
        "# =============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
        "fig.suptitle('üìä Quando os Gigantes Enviam Emails?\\nAn√°lise de 500.000+ emails',\n",
        "             fontsize=20, fontweight='bold', color='white', y=1.02)\n",
        "\n",
        "for idx, (category, timestamps_list) in enumerate(category_data.items()):\n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "\n",
        "    hours = [ts.hour for ts in timestamps_list]\n",
        "    hour_counts = Counter(hours)\n",
        "\n",
        "    x = list(range(24))\n",
        "    y = [hour_counts.get(h, 0) for h in x]\n",
        "\n",
        "    color = COLORS.get(category, '#FFFFFF')\n",
        "    bars = ax.bar(x, y, color=color, alpha=0.8, edgecolor='white', linewidth=0.5)\n",
        "\n",
        "    # Destaca o hor√°rio de pico\n",
        "    max_hour = max(hour_counts, key=hour_counts.get)\n",
        "    bars[max_hour].set_color('#FFFFFF')\n",
        "    bars[max_hour].set_alpha(1)\n",
        "\n",
        "    ax.set_title(f'{category}\\n({len(timestamps_list):,} emails)',\n",
        "                 fontsize=14, fontweight='bold', color=color)\n",
        "    ax.set_xlabel('Hora (Bras√≠lia)', fontsize=10)\n",
        "    ax.set_ylabel('Quantidade', fontsize=10)\n",
        "    ax.set_xticks(range(0, 24, 2))\n",
        "    ax.set_xticklabels([f'{h}h' for h in range(0, 24, 2)])\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Anota√ß√£o do pico\n",
        "    ax.annotate(f'PICO: {max_hour}h', xy=(max_hour, hour_counts[max_hour]),\n",
        "                xytext=(max_hour + 2, hour_counts[max_hour] * 1.1),\n",
        "                fontsize=11, color='white', fontweight='bold',\n",
        "                arrowprops=dict(arrowstyle='->', color='white', lw=1.5))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('grafico1_visao_geral.png', dpi=150, bbox_inches='tight',\n",
        "            facecolor='#0a0a0a', edgecolor='none')\n",
        "plt.show()\n",
        "print(\"üìÅ Salvo: grafico1_visao_geral.png\")\n",
        "\n",
        "# =============================================================================\n",
        "# GR√ÅFICO 2: COMPARATIVO HORA A HORA (TODAS CATEGORIAS)\n",
        "# =============================================================================\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "x = np.arange(24)\n",
        "width = 0.2\n",
        "multiplier = 0\n",
        "\n",
        "for category, timestamps_list in category_data.items():\n",
        "    hours = [ts.hour for ts in timestamps_list]\n",
        "    hour_counts = Counter(hours)\n",
        "    total = len(timestamps_list)\n",
        "\n",
        "    # Normaliza para percentual\n",
        "    y = [(hour_counts.get(h, 0) / total * 100) for h in range(24)]\n",
        "\n",
        "    offset = width * multiplier\n",
        "    color = COLORS.get(category, '#FFFFFF')\n",
        "    ax.bar(x + offset, y, width, label=category, color=color, alpha=0.85)\n",
        "    multiplier += 1\n",
        "\n",
        "ax.set_xlabel('Hora (Bras√≠lia)', fontsize=12)\n",
        "ax.set_ylabel('% dos emails da categoria', fontsize=12)\n",
        "ax.set_title('üìà Distribui√ß√£o Hor√°ria: Portais vs Redes Sociais vs Consultorias vs Big Techs\\n',\n",
        "             fontsize=16, fontweight='bold')\n",
        "ax.set_xticks(x + width * 1.5)\n",
        "ax.set_xticklabels([f'{h}h' for h in range(24)])\n",
        "ax.legend(loc='upper right', fontsize=11)\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('grafico2_comparativo.png', dpi=150, bbox_inches='tight',\n",
        "            facecolor='#0a0a0a', edgecolor='none')\n",
        "plt.show()\n",
        "print(\"üìÅ Salvo: grafico2_comparativo.png\")\n",
        "\n",
        "# =============================================================================\n",
        "# GR√ÅFICO 3: TOP FONTES INDIVIDUAIS\n",
        "# =============================================================================\n",
        "\n",
        "# Pega top 15 fontes por volume\n",
        "top_sources = sorted(source_data.items(), key=lambda x: len(x[1]), reverse=True)[:15]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 10))\n",
        "\n",
        "sources_names = []\n",
        "sources_hours = []\n",
        "sources_counts = []\n",
        "sources_colors = []\n",
        "\n",
        "for source_name, timestamps_list in top_sources:\n",
        "    hours = [ts.hour for ts in timestamps_list]\n",
        "    most_common_hour = Counter(hours).most_common(1)[0][0]\n",
        "\n",
        "    sources_names.append(source_name)\n",
        "    sources_hours.append(most_common_hour)\n",
        "    sources_counts.append(len(timestamps_list))\n",
        "\n",
        "    # Determina cor pela categoria\n",
        "    for ts, frm, cat, src in all_senders:\n",
        "        if src == source_name:\n",
        "            sources_colors.append(COLORS.get(cat, '#FFFFFF'))\n",
        "            break\n",
        "\n",
        "# Ordena por hor√°rio preferido\n",
        "sorted_data = sorted(zip(sources_names, sources_hours, sources_counts, sources_colors),\n",
        "                     key=lambda x: x[1])\n",
        "\n",
        "y_pos = np.arange(len(sorted_data))\n",
        "names = [d[0] for d in sorted_data]\n",
        "hours = [d[1] for d in sorted_data]\n",
        "counts = [d[2] for d in sorted_data]\n",
        "colors = [d[3] for d in sorted_data]\n",
        "\n",
        "bars = ax.barh(y_pos, hours, color=colors, alpha=0.85, edgecolor='white', linewidth=0.5)\n",
        "\n",
        "ax.set_yticks(y_pos)\n",
        "ax.set_yticklabels([f'{name} ({count:,})' for name, count in zip(names, counts)], fontsize=11)\n",
        "ax.set_xlabel('Hor√°rio Preferido de Envio (Bras√≠lia)', fontsize=12)\n",
        "ax.set_title('üéØ Hor√°rio Favorito dos Top 15 Remetentes\\n(ordenado por hora)',\n",
        "             fontsize=16, fontweight='bold')\n",
        "ax.set_xlim(0, 24)\n",
        "ax.set_xticks(range(0, 25, 2))\n",
        "ax.set_xticklabels([f'{h}h' for h in range(0, 25, 2)])\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Adiciona hora no final da barra\n",
        "for i, (bar, hour) in enumerate(zip(bars, hours)):\n",
        "    ax.text(hour + 0.3, bar.get_y() + bar.get_height()/2, f'{hour}h',\n",
        "            va='center', fontsize=10, fontweight='bold', color='white')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('grafico3_top_fontes.png', dpi=150, bbox_inches='tight',\n",
        "            facecolor='#0a0a0a', edgecolor='none')\n",
        "plt.show()\n",
        "print(\"üìÅ Salvo: grafico3_top_fontes.png\")\n",
        "\n",
        "# =============================================================================\n",
        "# GR√ÅFICO 4: HEATMAP HORA x DIA DA SEMANA (AGREGADO)\n",
        "# =============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
        "\n",
        "for idx, (category, timestamps_list) in enumerate(category_data.items()):\n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "\n",
        "    # Matriz hora x dia\n",
        "    matrix = np.zeros((7, 24))\n",
        "    for ts in timestamps_list:\n",
        "        matrix[ts.weekday()][ts.hour] += 1\n",
        "\n",
        "    # Normaliza por linha (dia)\n",
        "    row_sums = matrix.sum(axis=1, keepdims=True)\n",
        "    matrix_pct = np.divide(matrix, row_sums, where=row_sums!=0) * 100\n",
        "\n",
        "    color = COLORS.get(category, '#FFFFFF')\n",
        "    cmap = plt.cm.colors.LinearSegmentedColormap.from_list('custom', ['#0a0a0a', color])\n",
        "\n",
        "    im = ax.imshow(matrix_pct, cmap=cmap, aspect='auto')\n",
        "\n",
        "    ax.set_xticks(range(0, 24, 2))\n",
        "    ax.set_xticklabels([f'{h}h' for h in range(0, 24, 2)])\n",
        "    ax.set_yticks(range(7))\n",
        "    ax.set_yticklabels([DIAS_PT[d] for d in range(7)])\n",
        "    ax.set_xlabel('Hora', fontsize=10)\n",
        "    ax.set_title(f'{category}', fontsize=14, fontweight='bold', color=color)\n",
        "\n",
        "    # Marca o pico de cada dia\n",
        "    for day in range(7):\n",
        "        max_hour = np.argmax(matrix_pct[day])\n",
        "        if matrix_pct[day][max_hour] > 0:\n",
        "            ax.plot(max_hour, day, 'w*', markersize=12)\n",
        "\n",
        "fig.suptitle('üóìÔ∏è Heatmap: Quando Cada Categoria Envia por Dia da Semana\\n(‚òÖ = pico do dia)',\n",
        "             fontsize=18, fontweight='bold', y=1.02)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('grafico4_heatmap.png', dpi=150, bbox_inches='tight',\n",
        "            facecolor='#0a0a0a', edgecolor='none')\n",
        "plt.show()\n",
        "print(\"üìÅ Salvo: grafico4_heatmap.png\")\n",
        "\n",
        "# =============================================================================\n",
        "# GR√ÅFICO 5: REDES SOCIAIS - DETALHADO\n",
        "# =============================================================================\n",
        "\n",
        "social_sources = {k: v for k, v in source_data.items()\n",
        "                  if any(k == SOCIAL_NETWORKS.get(key) for key in SOCIAL_NETWORKS)}\n",
        "\n",
        "if social_sources:\n",
        "    fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "    x = np.arange(24)\n",
        "\n",
        "    for source_name, timestamps_list in sorted(social_sources.items(),\n",
        "                                                key=lambda x: len(x[1]), reverse=True)[:8]:\n",
        "        hours = [ts.hour for ts in timestamps_list]\n",
        "        hour_counts = Counter(hours)\n",
        "        total = len(timestamps_list)\n",
        "        y = [(hour_counts.get(h, 0) / total * 100) for h in range(24)]\n",
        "        ax.plot(x, y, marker='o', linewidth=2, markersize=4,\n",
        "                label=f'{source_name} ({total:,})', alpha=0.8)\n",
        "\n",
        "    ax.set_xlabel('Hora (Bras√≠lia)', fontsize=12)\n",
        "    ax.set_ylabel('% dos emails', fontsize=12)\n",
        "    ax.set_title('üì± Redes Sociais: Quando Cada Uma Envia Notifica√ß√µes?\\n',\n",
        "                 fontsize=16, fontweight='bold')\n",
        "    ax.set_xticks(range(24))\n",
        "    ax.set_xticklabels([f'{h}h' for h in range(24)])\n",
        "    ax.legend(loc='upper right', fontsize=10)\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('grafico5_redes_sociais.png', dpi=150, bbox_inches='tight',\n",
        "                facecolor='#0a0a0a', edgecolor='none')\n",
        "    plt.show()\n",
        "    print(\"üìÅ Salvo: grafico5_redes_sociais.png\")\n",
        "\n",
        "# =============================================================================\n",
        "# GR√ÅFICO 6: PORTAIS DE NOT√çCIAS - DETALHADO\n",
        "# =============================================================================\n",
        "\n",
        "news_sources = {k: v for k, v in source_data.items()\n",
        "                if any(k == NEWS_PORTALS.get(key) for key in NEWS_PORTALS)}\n",
        "\n",
        "if news_sources:\n",
        "    fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "    x = np.arange(24)\n",
        "\n",
        "    for source_name, timestamps_list in sorted(news_sources.items(),\n",
        "                                                key=lambda x: len(x[1]), reverse=True)[:10]:\n",
        "        hours = [ts.hour for ts in timestamps_list]\n",
        "        hour_counts = Counter(hours)\n",
        "        total = len(timestamps_list)\n",
        "        y = [(hour_counts.get(h, 0) / total * 100) for h in range(24)]\n",
        "        ax.plot(x, y, marker='o', linewidth=2, markersize=4,\n",
        "                label=f'{source_name} ({total:,})', alpha=0.8)\n",
        "\n",
        "    ax.set_xlabel('Hora (Bras√≠lia)', fontsize=12)\n",
        "    ax.set_ylabel('% dos emails', fontsize=12)\n",
        "    ax.set_title('üì∞ Portais de Not√≠cias: Hor√°rio de Envio das Newsletters\\n',\n",
        "                 fontsize=16, fontweight='bold')\n",
        "    ax.set_xticks(range(24))\n",
        "    ax.set_xticklabels([f'{h}h' for h in range(24)])\n",
        "    ax.legend(loc='upper right', fontsize=10)\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('grafico6_portais_noticias.png', dpi=150, bbox_inches='tight',\n",
        "                facecolor='#0a0a0a', edgecolor='none')\n",
        "    plt.show()\n",
        "    print(\"üìÅ Salvo: grafico6_portais_noticias.png\")\n",
        "\n",
        "# =============================================================================\n",
        "# AN√ÅLISE TEXTUAL PARA LINKEDIN\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìù TEXTO PARA LINKEDIN\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\"\"\n",
        "üîç Analisei mais de 500.000 emails que recebi nos √∫ltimos anos para descobrir:\n",
        "\n",
        "**Quando os gigantes da comunica√ß√£o enviam seus emails?**\n",
        "\n",
        "üìä PRINCIPAIS DESCOBERTAS:\n",
        "\"\"\")\n",
        "\n",
        "for category, timestamps_list in category_data.items():\n",
        "    hours = [ts.hour for ts in timestamps_list]\n",
        "    hour_counts = Counter(hours)\n",
        "    top_hours = hour_counts.most_common(3)\n",
        "\n",
        "    weekdays = [ts.weekday() for ts in timestamps_list]\n",
        "    weekday_counts = Counter(weekdays)\n",
        "    top_day = weekday_counts.most_common(1)[0]\n",
        "\n",
        "    print(f\"\\n{'üì∞' if 'Not√≠cias' in category else 'üì±' if 'Sociais' in category else 'üíº' if 'Consult' in category else 'üñ•Ô∏è'} {category.upper()}\")\n",
        "    print(f\"   ‚Ä¢ Hor√°rio favorito: {top_hours[0][0]}h ({top_hours[0][1]:,} emails)\")\n",
        "    print(f\"   ‚Ä¢ Top 3 hor√°rios: {top_hours[0][0]}h, {top_hours[1][0]}h, {top_hours[2][0]}h\")\n",
        "    print(f\"   ‚Ä¢ Dia preferido: {DIAS_FULL[top_day[0]]} ({top_day[1]:,} emails)\")\n",
        "    print(f\"   ‚Ä¢ Total analisado: {len(timestamps_list):,} emails\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"\\nüéØ TOP 10 REMETENTES E SEUS HOR√ÅRIOS FAVORITOS:\\n\")\n",
        "\n",
        "for i, (source_name, timestamps_list) in enumerate(sorted(source_data.items(),\n",
        "                                                           key=lambda x: len(x[1]),\n",
        "                                                           reverse=True)[:10], 1):\n",
        "    hours = [ts.hour for ts in timestamps_list]\n",
        "    top_hour = Counter(hours).most_common(1)[0][0]\n",
        "    print(f\"   {i:2}. {source_name}: {top_hour}h ({len(timestamps_list):,} emails)\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"\\nüí° INSIGHTS:\")\n",
        "\n",
        "# Calcula hor√°rios mais vazios\n",
        "all_timestamps = [ts for ts_list in category_data.values() for ts in ts_list]\n",
        "all_hours = Counter([ts.hour for ts in all_timestamps])\n",
        "empty_hours = sorted(all_hours.items(), key=lambda x: x[1])[:5]\n",
        "\n",
        "# =============================================================================\n",
        "# INSIGHTS DIN√ÇMICOS (BASEADOS NOS DADOS REAIS)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüí° INSIGHTS (baseados nos dados):\\n\")\n",
        "\n",
        "# Descobre hor√°rio de pico de cada categoria\n",
        "for category, timestamps_list in category_data.items():\n",
        "    hours = [ts.hour for ts in timestamps_list]\n",
        "    hour_counts = Counter(hours)\n",
        "\n",
        "    # Agrupa por per√≠odo\n",
        "    manha = sum(hour_counts.get(h, 0) for h in range(6, 12))      # 6h-11h\n",
        "    tarde = sum(hour_counts.get(h, 0) for h in range(12, 18))     # 12h-17h\n",
        "    noite = sum(hour_counts.get(h, 0) for h in range(18, 24))     # 18h-23h\n",
        "    madrugada = sum(hour_counts.get(h, 0) for h in range(0, 6))   # 0h-5h\n",
        "    total = len(timestamps_list)\n",
        "\n",
        "    periodos = [\n",
        "        ('manh√£ (6h-11h)', manha),\n",
        "        ('tarde (12h-17h)', tarde),\n",
        "        ('noite (18h-23h)', noite),\n",
        "        ('madrugada (0h-5h)', madrugada)\n",
        "    ]\n",
        "    periodo_top = max(periodos, key=lambda x: x[1])\n",
        "    pct = (periodo_top[1] / total * 100) if total > 0 else 0\n",
        "\n",
        "    top_hour = hour_counts.most_common(1)[0][0]\n",
        "\n",
        "    print(f\"‚Ä¢ {category}: concentra {pct:.0f}% dos envios na {periodo_top[0]}, pico √†s {top_hour}h\")\n",
        "\n",
        "# Hor√°rios com menor volume (oportunidade)\n",
        "all_hours = Counter([ts.hour for ts_list in category_data.values() for ts in ts_list])\n",
        "if all_hours:\n",
        "    empty_hours = sorted(all_hours.items(), key=lambda x: x[1])[:5]\n",
        "    print(f\"\\n‚Ä¢ Hor√°rios com MENOR concorr√™ncia: {', '.join([f'{h}h' for h, c in empty_hours])}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìÅ GR√ÅFICOS SALVOS:\")\n",
        "print(\"   ‚Ä¢ grafico1_visao_geral.png\")\n",
        "print(\"   ‚Ä¢ grafico2_comparativo.png\")\n",
        "print(\"   ‚Ä¢ grafico3_top_fontes.png\")\n",
        "print(\"   ‚Ä¢ grafico4_heatmap.png\")\n",
        "print(\"   ‚Ä¢ grafico5_redes_sociais.png\")\n",
        "print(\"   ‚Ä¢ grafico6_portais_noticias.png\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Download autom√°tico\n",
        "try:\n",
        "    from google.colab import files\n",
        "    for f in ['grafico1_visao_geral.png', 'grafico2_comparativo.png',\n",
        "              'grafico3_top_fontes.png', 'grafico4_heatmap.png',\n",
        "              'grafico5_redes_sociais.png', 'grafico6_portais_noticias.png']:\n",
        "        files.download(f)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "print(\"\\n‚úÖ An√°lise completa!\")"
      ]
    }
  ]
}